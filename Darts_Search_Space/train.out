Experiment dir : /sdb_new/wz/NAS/AGNAS/Darts_Search_Space/eval/eval-EXP-20231208-221247
using cuda:0 device.
12/08 10:12:50 PM gpu device = 0
12/08 10:12:50 PM args = Namespace(data='/sdb_new/wz/dataset/ISIC-2017', dataset='isic2017', batch_size=8, learning_rate=0.025, momentum=0.9, weight_decay=0.0003, report_freq=50, gpu=0, epochs=200, init_channels=36, layers=2, model_path='saved_models', auxiliary=False, auxiliary_weight=0.4, cutout=True, cutout_length=16, drop_path_prob=0.2, save='/sdb_new/wz/NAS/AGNAS/Darts_Search_Space/eval/eval-EXP-20231208-221247', seed=1, train_portion=0.7, arch='AGNAS', grad_clip=5)
12/08 10:12:50 PM genotype = [Normal_Genotype(normal=[('skip_connect', 1), ('skip_connect', 0), ('eca', 0), ('eca', 2), ('max_pool_3x3', 3), ('skip_connect', 2), ('cbam', 3), ('max_pool_3x3', 4)], normal_concat=range(2, 6)), Reduce_Genotype(reduce=[('cbam', 1), ('dil_conv_3x3', 0), ('sep_conv_3x3', 2), ('eca', 1), ('sep_conv_3x3', 3), ('sep_conv_3x3', 1), ('eca', 4), ('cbam', 3)], reduce_concat=range(2, 6)), Normal_Genotype(normal=[('eca', 1), ('avg_pool_3x3', 0), ('avg_pool_3x3', 1), ('sep_conv_3x3', 2), ('cbam', 3), ('cbam', 2), ('cbam', 4), ('dil_conv_3x3', 3)], normal_concat=range(2, 6)), Reduce_Genotype(reduce=[('sep_conv_3x3', 1), ('max_pool_3x3', 0), ('skip_connect', 2), ('avg_pool_3x3', 0), ('max_pool_3x3', 3), ('skip_connect', 2), ('avg_pool_3x3', 4), ('dil_conv_3x3', 3)], reduce_concat=range(2, 6)), Normal_Genotype(normal=[('cbam', 1), ('dil_conv_3x3', 0), ('avg_pool_3x3', 2), ('sep_conv_3x3', 0), ('cbam', 0), ('max_pool_3x3', 2), ('sep_conv_3x3', 4), ('skip_connect', 3)], normal_concat=range(2, 6))]
108 108 72
108 288 144
12/08 10:12:53 PM NetworkCIFAR(
  (stem): Sequential(
    (0): Conv2d(3, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (cells): ModuleList(
    (0): Cell(
      (preprocess0): ReLUConvBN(
        (op): Sequential(
          (0): ReLU()
          (1): Conv2d(108, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (preprocess1): ReLUConvBN(
        (op): Sequential(
          (0): ReLU()
          (1): Conv2d(108, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (_ops): ModuleList(
        (0): CBAM(
          (ChannelGate): ChannelGate(
            (mlp): Sequential(
              (0): Flatten()
              (1): Linear(in_features=72, out_features=4, bias=True)
              (2): ReLU()
              (3): Linear(in_features=4, out_features=72, bias=True)
            )
          )
          (SpatialGate): SpatialGate(
            (compress): ChannelPool()
            (spatial): BasicConv(
              (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
          (avg): AvgPool2d(kernel_size=3, stride=2, padding=1)
        )
        (1): DilConv(
          (op): Sequential(
            (0): ReLU()
            (1): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2), dilation=(2, 2), groups=72, bias=False)
            (2): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): SepConv(
          (op): Sequential(
            (0): ReLU()
            (1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
            (2): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
            (6): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): eca(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (sigmoid): Sigmoid()
          (avg): AvgPool2d(kernel_size=3, stride=2, padding=1)
        )
        (4): SepConv(
          (op): Sequential(
            (0): ReLU()
            (1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
            (2): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
            (6): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): SepConv(
          (op): Sequential(
            (0): ReLU()
            (1): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
            (2): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
            (6): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (6): eca(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (sigmoid): Sigmoid()
        )
        (7): CBAM(
          (ChannelGate): ChannelGate(
            (mlp): Sequential(
              (0): Flatten()
              (1): Linear(in_features=72, out_features=4, bias=True)
              (2): ReLU()
              (3): Linear(in_features=4, out_features=72, bias=True)
            )
          )
          (SpatialGate): SpatialGate(
            (compress): ChannelPool()
            (spatial): BasicConv(
              (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
    )
    (1): Cell(
      (preprocess0): FactorizedReduce(
        (relu): ReLU()
        (conv_1): Conv2d(108, 72, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (conv_2): Conv2d(108, 72, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (preprocess1): ReLUConvBN(
        (op): Sequential(
          (0): ReLU()
          (1): Conv2d(288, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (_ops): ModuleList(
        (0): SepConv(
          (op): Sequential(
            (0): ReLU()
            (1): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (2): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (3): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (6): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (2): Identity()
        (3): AvgPool2d(kernel_size=3, stride=2, padding=1)
        (4): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
        (5): Identity()
        (6): AvgPool2d(kernel_size=3, stride=1, padding=1)
        (7): DilConv(
          (op): Sequential(
            (0): ReLU()
            (1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=144, bias=False)
            (2): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (3): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (global_pooling): AdaptiveAvgPool2d(output_size=1)
  (classifier): Linear(in_features=576, out_features=3, bias=True)
)
12/08 10:12:53 PM param size = 0.188605MB
/home/wz/.conda/envs/federated/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/wz/.conda/envs/federated/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:807: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
train-num: 2000
valid-num: 150
Using 8 dataloader workers every process
12/08 10:12:53 PM epoch 0 lr 2.499692e-02
/home/wz/.conda/envs/federated/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/sdb_new/wz/NAS/AGNAS/Darts_Search_Space/train.py:202: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)
12/08 10:12:57 PM train 000 1.833869e+00 0.000000
12/08 10:13:12 PM train 050 1.959092e+00 52.696078
12/08 10:13:26 PM train 100 1.784207e+00 54.455446
12/08 10:13:41 PM train 150 1.619387e+00 53.973510
12/08 10:13:57 PM train 200 1.487083e+00 56.592040
12/08 10:14:13 PM train_acc 56.850000
12/08 10:14:16 PM valid 000 2.629348e+00 25.000000
12/08 10:14:23 PM valid_acc 51.333333
12/08 10:14:23 PM best_valid_acc 51.333333
12/08 10:14:23 PM epoch 1 lr 2.498921e-02
12/08 10:14:25 PM train 000 1.306701e+00 50.000000
12/08 10:14:41 PM train 050 1.020282e+00 63.235294
12/08 10:14:56 PM train 100 9.842881e-01 63.366337
12/08 10:15:12 PM train 150 9.767107e-01 62.168874
12/08 10:15:27 PM train 200 9.548942e-01 62.997512
12/08 10:15:42 PM train_acc 65.000000
12/08 10:15:47 PM valid 000 9.563880e-01 62.500000
12/08 10:15:53 PM valid_acc 52.000000
12/08 10:15:53 PM best_valid_acc 52.000000
12/08 10:15:53 PM epoch 2 lr 2.497842e-02
12/08 10:15:55 PM train 000 8.932343e-01 62.500000
12/08 10:16:11 PM train 050 9.120344e-01 63.725490
12/08 10:16:26 PM train 100 8.779057e-01 66.212871
12/08 10:16:41 PM train 150 9.018661e-01 64.569536
12/08 10:16:57 PM train 200 8.917667e-01 65.671642
12/08 10:17:12 PM train_acc 65.600000
12/08 10:17:15 PM valid 000 1.213185e+00 50.000000
12/08 10:17:23 PM valid_acc 52.000000
12/08 10:17:23 PM best_valid_acc 52.000000
12/08 10:17:23 PM epoch 3 lr 2.496455e-02
12/08 10:17:25 PM train 000 7.205368e-01 75.000000
12/08 10:17:41 PM train 050 8.157541e-01 69.607843
12/08 10:17:56 PM train 100 8.325212e-01 68.564356
12/08 10:18:11 PM train 150 8.438337e-01 68.294702
12/08 10:18:27 PM train 200 8.626224e-01 67.537313
12/08 10:18:42 PM train_acc 67.150000
12/08 10:18:46 PM valid 000 7.645727e-01 75.000000
12/08 10:18:52 PM valid_acc 52.000000
12/08 10:18:52 PM best_valid_acc 52.000000
12/08 10:18:52 PM epoch 4 lr 2.494761e-02
12/08 10:18:53 PM train 000 9.530210e-01 62.500000
12/08 10:19:11 PM train 050 8.320598e-01 71.078431
12/08 10:19:26 PM train 100 8.555919e-01 68.193069
12/08 10:19:41 PM train 150 8.708948e-01 67.218543
12/08 10:19:56 PM train 200 8.592720e-01 67.288557
12/08 10:20:11 PM train_acc 67.100000
12/08 10:20:15 PM valid 000 1.149402e+00 37.500000
12/08 10:20:23 PM valid_acc 53.333333
12/08 10:20:23 PM best_valid_acc 53.333333
12/08 10:20:23 PM epoch 5 lr 2.492759e-02
12/08 10:20:26 PM train 000 6.519312e-01 75.000000
12/08 10:20:41 PM train 050 8.077408e-01 70.833333
12/08 10:20:56 PM train 100 8.353641e-01 68.440594
12/08 10:21:12 PM train 150 8.556182e-01 66.970199
12/08 10:21:27 PM train 200 8.577443e-01 66.853234
12/08 10:21:42 PM train_acc 67.500000
12/08 10:21:46 PM valid 000 1.007030e+00 62.500000
12/08 10:21:52 PM valid_acc 55.333333
12/08 10:21:52 PM best_valid_acc 55.333333
12/08 10:21:52 PM epoch 6 lr 2.490452e-02
12/08 10:21:55 PM train 000 6.757396e-01 62.500000
12/08 10:22:10 PM train 050 8.050025e-01 71.323529
12/08 10:22:26 PM train 100 8.336572e-01 69.059406
12/08 10:22:41 PM train 150 8.319682e-01 68.625828
12/08 10:22:56 PM train 200 8.304458e-01 68.034826
12/08 10:23:11 PM train_acc 67.500000
12/08 10:23:15 PM valid 000 9.115773e-01 50.000000
12/08 10:23:25 PM valid_acc 52.000000
12/08 10:23:25 PM best_valid_acc 55.333333
12/08 10:23:25 PM epoch 7 lr 2.487838e-02
12/08 10:23:28 PM train 000 9.721527e-01 50.000000
12/08 10:23:45 PM train 050 8.447201e-01 67.892157
12/08 10:24:00 PM train 100 8.442217e-01 67.821782
12/08 10:24:16 PM train 150 8.502615e-01 67.384106
12/08 10:24:31 PM train 200 8.348840e-01 68.159204
12/08 10:24:46 PM train_acc 67.850000
12/08 10:24:51 PM valid 000 6.940870e-01 75.000000
12/08 10:24:57 PM valid_acc 52.000000
12/08 10:24:57 PM best_valid_acc 55.333333
12/08 10:24:57 PM epoch 8 lr 2.484919e-02
12/08 10:24:59 PM train 000 1.079189e+00 37.500000
12/08 10:25:17 PM train 050 8.008971e-01 69.117647
12/08 10:25:32 PM train 100 8.243854e-01 66.955446
12/08 10:25:47 PM train 150 8.316342e-01 66.804636
12/08 10:26:03 PM train 200 8.228995e-01 67.101990
12/08 10:26:18 PM train_acc 67.050000
12/08 10:26:21 PM valid 000 8.829931e-01 50.000000
12/08 10:26:30 PM valid_acc 53.333333
12/08 10:26:30 PM best_valid_acc 55.333333
12/08 10:26:30 PM epoch 9 lr 2.481695e-02
12/08 10:26:31 PM train 000 4.728228e-01 87.500000
12/08 10:26:48 PM train 050 8.186857e-01 68.137255
12/08 10:27:04 PM train 100 7.897205e-01 70.049505
12/08 10:27:19 PM train 150 7.923292e-01 68.956954
12/08 10:27:34 PM train 200 8.079059e-01 68.470149
12/08 10:27:49 PM train_acc 67.650000
12/08 10:27:53 PM valid 000 1.543209e+00 37.500000
12/08 10:28:01 PM valid_acc 52.000000
12/08 10:28:01 PM best_valid_acc 55.333333
12/08 10:28:01 PM epoch 10 lr 2.478167e-02
12/08 10:28:05 PM train 000 6.619573e-01 75.000000
12/08 10:28:20 PM train 050 7.895118e-01 70.343137
12/08 10:28:36 PM train 100 8.309296e-01 67.945545
12/08 10:28:51 PM train 150 8.254620e-01 67.798013
12/08 10:29:07 PM train 200 8.387929e-01 66.417910
12/08 10:29:22 PM train_acc 67.350000
12/08 10:29:27 PM valid 000 1.370125e+00 25.000000
12/08 10:29:35 PM valid_acc 53.333333
12/08 10:29:35 PM best_valid_acc 55.333333
12/08 10:29:35 PM epoch 11 lr 2.474336e-02
12/08 10:29:38 PM train 000 1.505162e+00 37.500000
12/08 10:29:53 PM train 050 7.856576e-01 66.176471
12/08 10:30:08 PM train 100 8.141589e-01 66.212871
12/08 10:30:23 PM train 150 8.077689e-01 67.466887
12/08 10:30:39 PM train 200 8.215133e-01 66.417910
12/08 10:30:54 PM train_acc 66.700000
12/08 10:30:59 PM valid 000 1.305843e+00 37.500000
12/08 10:31:06 PM valid_acc 51.333333
12/08 10:31:06 PM best_valid_acc 55.333333
12/08 10:31:06 PM epoch 12 lr 2.470204e-02
12/08 10:31:07 PM train 000 6.149666e-01 87.500000
12/08 10:31:25 PM train 050 8.011325e-01 69.852941
12/08 10:31:40 PM train 100 8.163599e-01 68.935644
12/08 10:31:55 PM train 150 8.357482e-01 66.970199
12/08 10:32:11 PM train 200 8.369308e-01 67.101990
12/08 10:32:26 PM train_acc 66.900000
12/08 10:32:32 PM valid 000 1.261296e+00 50.000000
12/08 10:32:38 PM valid_acc 52.666667
12/08 10:32:38 PM best_valid_acc 55.333333
12/08 10:32:38 PM epoch 13 lr 2.465770e-02
12/08 10:32:41 PM train 000 6.219879e-01 87.500000
12/08 10:32:57 PM train 050 8.374952e-01 67.647059
12/08 10:33:13 PM train 100 8.004805e-01 69.801980
12/08 10:33:28 PM train 150 8.082086e-01 68.708609
12/08 10:33:43 PM train 200 8.165012e-01 68.283582
12/08 10:33:58 PM train_acc 68.000000
12/08 10:34:01 PM valid 000 7.094805e-01 75.000000
12/08 10:34:11 PM valid_acc 53.333333
12/08 10:34:11 PM best_valid_acc 55.333333
12/08 10:34:11 PM epoch 14 lr 2.461037e-02
12/08 10:34:13 PM train 000 8.218101e-01 62.500000
12/08 10:34:30 PM train 050 7.622812e-01 72.058824
12/08 10:34:46 PM train 100 7.958530e-01 69.678218
12/08 10:35:01 PM train 150 8.084863e-01 68.211921
12/08 10:35:16 PM train 200 8.161311e-01 67.786070
12/08 10:35:31 PM train_acc 67.800000
12/08 10:35:34 PM valid 000 1.686803e+00 25.000000
12/08 10:35:43 PM valid_acc 52.000000
12/08 10:35:43 PM best_valid_acc 55.333333
12/08 10:35:43 PM epoch 15 lr 2.456005e-02
12/08 10:35:46 PM train 000 4.663430e-01 87.500000
12/08 10:36:04 PM train 050 8.068689e-01 70.343137
12/08 10:36:20 PM train 100 8.084791e-01 67.821782
12/08 10:36:35 PM train 150 8.179390e-01 67.384106
12/08 10:36:51 PM train 200 8.263045e-01 66.915423
12/08 10:37:06 PM train_acc 67.450000
12/08 10:37:11 PM valid 000 1.013334e+00 62.500000
12/08 10:37:18 PM valid_acc 52.000000
12/08 10:37:18 PM best_valid_acc 55.333333
12/08 10:37:18 PM epoch 16 lr 2.450675e-02
12/08 10:37:21 PM train 000 7.436097e-01 75.000000
12/08 10:37:37 PM train 050 7.701922e-01 72.058824
12/08 10:37:52 PM train 100 8.127076e-01 68.440594
12/08 10:38:08 PM train 150 8.136919e-01 67.715232
12/08 10:38:23 PM train 200 8.240873e-01 67.101990
12/08 10:38:38 PM train_acc 68.000000
12/08 10:38:41 PM valid 000 1.032633e+00 37.500000
12/08 10:38:49 PM valid_acc 57.333333
12/08 10:38:49 PM best_valid_acc 57.333333
12/08 10:38:49 PM epoch 17 lr 2.445049e-02
12/08 10:38:52 PM train 000 5.360964e-01 87.500000
12/08 10:39:08 PM train 050 7.587405e-01 71.078431
12/08 10:39:23 PM train 100 7.840613e-01 69.801980
12/08 10:39:39 PM train 150 7.877264e-01 69.205298
12/08 10:39:54 PM train 200 8.025161e-01 68.594527
12/08 10:40:09 PM train_acc 67.700000
12/08 10:40:13 PM valid 000 8.513745e-01 75.000000
12/08 10:40:21 PM valid_acc 52.000000
12/08 10:40:21 PM best_valid_acc 57.333333
12/08 10:40:21 PM epoch 18 lr 2.439128e-02
12/08 10:40:23 PM train 000 7.065679e-01 75.000000
12/08 10:40:41 PM train 050 8.648920e-01 66.421569
12/08 10:40:57 PM train 100 8.286517e-01 67.945545
12/08 10:41:13 PM train 150 8.104874e-01 68.708609
12/08 10:41:28 PM train 200 8.002914e-01 69.029851
12/08 10:41:43 PM train_acc 68.050000
12/08 10:41:47 PM valid 000 1.003737e+00 25.000000
12/08 10:41:56 PM valid_acc 53.333333
12/08 10:41:56 PM best_valid_acc 57.333333
12/08 10:41:57 PM epoch 19 lr 2.432914e-02
12/08 10:41:58 PM train 000 1.048335e+00 62.500000
12/08 10:42:15 PM train 050 7.850581e-01 71.078431
12/08 10:42:31 PM train 100 7.942303e-01 70.173267
12/08 10:42:46 PM train 150 8.034263e-01 68.874172
12/08 10:43:01 PM train 200 8.036374e-01 68.656716
12/08 10:43:16 PM train_acc 67.750000
12/08 10:43:20 PM valid 000 6.613932e-01 62.500000
12/08 10:43:28 PM valid_acc 52.000000
12/08 10:43:28 PM best_valid_acc 57.333333
12/08 10:43:28 PM epoch 20 lr 2.426409e-02
12/08 10:43:30 PM train 000 6.442422e-01 75.000000
12/08 10:43:46 PM train 050 7.977953e-01 68.382353
12/08 10:44:01 PM train 100 8.008793e-01 67.945545
12/08 10:44:16 PM train 150 7.992653e-01 67.549669
12/08 10:44:31 PM train 200 8.036274e-01 67.661692
12/08 10:44:46 PM train_acc 67.850000
12/08 10:44:50 PM valid 000 4.800100e-01 87.500000
12/08 10:44:58 PM valid_acc 52.000000
12/08 10:44:58 PM best_valid_acc 57.333333
12/08 10:44:58 PM epoch 21 lr 2.419613e-02
12/08 10:45:01 PM train 000 7.636560e-01 75.000000
12/08 10:45:17 PM train 050 8.691414e-01 65.196078
12/08 10:45:32 PM train 100 8.253863e-01 68.316832
12/08 10:45:47 PM train 150 8.277620e-01 67.963576
12/08 10:46:02 PM train 200 8.224580e-01 67.910448
12/08 10:46:17 PM train_acc 68.100000
12/08 10:46:22 PM valid 000 1.229040e+00 25.000000
12/08 10:46:30 PM valid_acc 52.000000
12/08 10:46:30 PM best_valid_acc 57.333333
12/08 10:46:30 PM epoch 22 lr 2.412528e-02
12/08 10:46:32 PM train 000 4.286475e-01 100.000000
12/08 10:46:48 PM train 050 7.521936e-01 73.284314
12/08 10:47:03 PM train 100 7.913846e-01 68.688119
12/08 10:47:19 PM train 150 8.056829e-01 67.880795
12/08 10:47:34 PM train 200 8.113661e-01 67.226368
12/08 10:47:49 PM train_acc 67.350000
12/08 10:47:52 PM valid 000 1.258764e+00 25.000000
12/08 10:48:00 PM valid_acc 52.000000
12/08 10:48:00 PM best_valid_acc 57.333333
12/08 10:48:00 PM epoch 23 lr 2.405157e-02
12/08 10:48:02 PM train 000 8.745327e-01 62.500000
12/08 10:48:20 PM train 050 7.970616e-01 69.362745
12/08 10:48:35 PM train 100 7.990515e-01 68.193069
12/08 10:48:50 PM train 150 7.983234e-01 68.294702
12/08 10:49:06 PM train 200 8.098047e-01 67.475124
12/08 10:49:21 PM train_acc 68.150000
12/08 10:49:25 PM valid 000 1.224242e+00 25.000000
12/08 10:49:33 PM valid_acc 52.000000
12/08 10:49:33 PM best_valid_acc 57.333333
12/08 10:49:33 PM epoch 24 lr 2.397501e-02
12/08 10:49:35 PM train 000 7.968997e-01 62.500000
12/08 10:49:50 PM train 050 8.307709e-01 65.196078
12/08 10:50:05 PM train 100 8.132893e-01 68.193069
12/08 10:50:21 PM train 150 8.045834e-01 68.791391
12/08 10:50:36 PM train 200 8.201950e-01 67.661692
12/08 10:50:51 PM train_acc 67.900000
12/08 10:50:57 PM valid 000 1.018994e+00 37.500000
12/08 10:51:03 PM valid_acc 56.666667
12/08 10:51:03 PM best_valid_acc 57.333333
12/08 10:51:03 PM epoch 25 lr 2.389562e-02
12/08 10:51:06 PM train 000 1.227203e+00 37.500000
12/08 10:51:22 PM train 050 8.075374e-01 67.647059
12/08 10:51:37 PM train 100 8.033094e-01 69.059406
12/08 10:51:53 PM train 150 8.093562e-01 68.791391
12/08 10:52:09 PM train 200 8.124325e-01 68.594527
12/08 10:52:24 PM train_acc 67.800000
12/08 10:52:28 PM valid 000 6.972357e-01 75.000000
12/08 10:52:34 PM valid_acc 53.333333
12/08 10:52:34 PM best_valid_acc 57.333333
12/08 10:52:34 PM epoch 26 lr 2.381341e-02
12/08 10:52:37 PM train 000 7.604604e-01 62.500000
12/08 10:52:52 PM train 050 8.243833e-01 67.156863
12/08 10:53:07 PM train 100 8.304792e-01 67.821782
12/08 10:53:23 PM train 150 8.336605e-01 66.307947
12/08 10:53:38 PM train 200 8.214377e-01 66.542289
12/08 10:53:53 PM train_acc 67.450000
12/08 10:53:57 PM valid 000 1.014671e+00 50.000000
12/08 10:54:06 PM valid_acc 52.000000
12/08 10:54:06 PM best_valid_acc 57.333333
12/08 10:54:06 PM epoch 27 lr 2.372842e-02
12/08 10:54:09 PM train 000 8.399687e-01 62.500000
12/08 10:54:25 PM train 050 8.167284e-01 69.852941
12/08 10:54:41 PM train 100 8.132982e-01 68.440594
12/08 10:54:56 PM train 150 8.081312e-01 68.377483
12/08 10:55:11 PM train 200 8.208998e-01 67.226368
12/08 10:55:26 PM train_acc 67.750000
12/08 10:55:29 PM valid 000 5.992559e-01 87.500000
12/08 10:55:37 PM valid_acc 57.333333
12/08 10:55:37 PM best_valid_acc 57.333333
12/08 10:55:37 PM epoch 28 lr 2.364065e-02
12/08 10:55:39 PM train 000 1.002753e+00 50.000000
12/08 10:55:56 PM train 050 8.027579e-01 68.627451
12/08 10:56:11 PM train 100 8.266959e-01 67.202970
12/08 10:56:26 PM train 150 8.116699e-01 67.963576
12/08 10:56:42 PM train 200 8.151805e-01 67.786070
12/08 10:56:57 PM train_acc 67.850000
12/08 10:57:00 PM valid 000 8.586671e-01 50.000000
12/08 10:57:09 PM valid_acc 52.000000
12/08 10:57:09 PM best_valid_acc 57.333333
12/08 10:57:09 PM epoch 29 lr 2.355014e-02
12/08 10:57:11 PM train 000 5.433372e-01 87.500000
12/08 10:57:28 PM train 050 7.918637e-01 67.892157
12/08 10:57:44 PM train 100 7.962547e-01 67.821782
12/08 10:57:59 PM train 150 7.966462e-01 67.880795
12/08 10:58:14 PM train 200 8.050808e-01 67.164179
12/08 10:58:31 PM train_acc 67.550000
12/08 10:58:34 PM valid 000 1.377756e+00 37.500000
12/08 10:58:41 PM valid_acc 52.000000
12/08 10:58:41 PM best_valid_acc 57.333333
12/08 10:58:41 PM epoch 30 lr 2.345691e-02
12/08 10:58:44 PM train 000 4.597798e-01 87.500000
12/08 10:59:01 PM train 050 8.109606e-01 67.401961
12/08 10:59:16 PM train 100 7.936414e-01 69.306931
12/08 10:59:32 PM train 150 7.903266e-01 69.205298
12/08 10:59:47 PM train 200 7.973732e-01 68.470149
12/08 11:00:02 PM train_acc 68.200000
12/08 11:00:05 PM valid 000 5.843354e-01 75.000000
12/08 11:00:14 PM valid_acc 52.000000
12/08 11:00:14 PM best_valid_acc 57.333333
12/08 11:00:14 PM epoch 31 lr 2.336097e-02
12/08 11:00:16 PM train 000 1.017322e+00 50.000000
12/08 11:00:33 PM train 050 8.406487e-01 63.725490
12/08 11:00:48 PM train 100 8.299188e-01 65.099010
12/08 11:01:03 PM train 150 8.053710e-01 67.218543
12/08 11:01:19 PM train 200 8.081700e-01 67.226368
12/08 11:01:34 PM train_acc 67.700000
12/08 11:01:37 PM valid 000 9.445247e-01 50.000000
12/08 11:01:44 PM valid_acc 56.000000
12/08 11:01:44 PM best_valid_acc 57.333333
12/08 11:01:44 PM epoch 32 lr 2.326235e-02
12/08 11:01:46 PM train 000 6.947253e-01 75.000000
12/08 11:02:04 PM train 050 8.009504e-01 67.156863
12/08 11:02:19 PM train 100 7.830449e-01 69.059406
12/08 11:02:34 PM train 150 7.805821e-01 68.460265
12/08 11:02:49 PM train 200 7.932431e-01 68.283582
12/08 11:03:04 PM train_acc 67.950000
12/08 11:03:09 PM valid 000 9.098657e-01 50.000000
12/08 11:03:17 PM valid_acc 52.000000
12/08 11:03:17 PM best_valid_acc 57.333333
12/08 11:03:17 PM epoch 33 lr 2.316107e-02
12/08 11:03:19 PM train 000 9.943752e-01 62.500000
12/08 11:03:36 PM train 050 8.034003e-01 66.911765
12/08 11:03:51 PM train 100 7.820850e-01 69.183168
12/08 11:04:06 PM train 150 7.997685e-01 68.211921
12/08 11:04:22 PM train 200 8.010032e-01 67.972637
12/08 11:04:38 PM train_acc 68.150000
12/08 11:04:44 PM valid 000 6.809781e-01 75.000000
12/08 11:04:50 PM valid_acc 52.000000
12/08 11:04:50 PM best_valid_acc 57.333333
12/08 11:04:50 PM epoch 34 lr 2.305717e-02
12/08 11:04:52 PM train 000 5.095941e-01 87.500000
12/08 11:05:08 PM train 050 7.594647e-01 71.323529
12/08 11:05:24 PM train 100 7.983548e-01 67.945545
12/08 11:05:39 PM train 150 7.974660e-01 68.129139
12/08 11:05:54 PM train 200 7.993063e-01 68.034826
12/08 11:06:10 PM train_acc 67.650000
12/08 11:06:14 PM valid 000 2.314982e+00 25.000000
12/08 11:06:22 PM valid_acc 52.000000
12/08 11:06:22 PM best_valid_acc 57.333333
12/08 11:06:22 PM epoch 35 lr 2.295066e-02
12/08 11:06:26 PM train 000 1.756848e+00 37.500000
12/08 11:06:41 PM train 050 8.371383e-01 65.931373
12/08 11:06:56 PM train 100 8.408360e-01 65.594059
12/08 11:07:12 PM train 150 8.214290e-01 67.384106
12/08 11:07:27 PM train 200 8.042190e-01 67.910448
12/08 11:07:42 PM train_acc 67.400000
12/08 11:07:47 PM valid 000 6.955565e-01 62.500000
12/08 11:07:54 PM valid_acc 52.000000
12/08 11:07:54 PM best_valid_acc 57.333333
12/08 11:07:54 PM epoch 36 lr 2.284158e-02
12/08 11:07:56 PM train 000 4.026123e-01 87.500000
12/08 11:08:15 PM train 050 8.083991e-01 67.647059
12/08 11:08:30 PM train 100 8.172957e-01 66.707921
12/08 11:08:46 PM train 150 8.073896e-01 67.466887
12/08 11:09:01 PM train 200 8.108024e-01 67.412935
12/08 11:09:16 PM train_acc 67.800000
12/08 11:09:21 PM valid 000 1.214135e+00 37.500000
12/08 11:09:30 PM valid_acc 52.666667
12/08 11:09:30 PM best_valid_acc 57.333333
12/08 11:09:30 PM epoch 37 lr 2.272994e-02
12/08 11:09:32 PM train 000 6.682039e-01 75.000000
12/08 11:09:49 PM train 050 7.798176e-01 69.117647
12/08 11:10:04 PM train 100 7.803975e-01 68.811881
12/08 11:10:19 PM train 150 7.760274e-01 69.784768
12/08 11:10:35 PM train 200 8.044688e-01 67.972637
12/08 11:10:50 PM train_acc 67.900000
12/08 11:10:54 PM valid 000 1.220439e+00 37.500000
12/08 11:11:04 PM valid_acc 52.000000
12/08 11:11:04 PM best_valid_acc 57.333333
12/08 11:11:04 PM epoch 38 lr 2.261578e-02
12/08 11:11:07 PM train 000 5.059415e-01 87.500000
12/08 11:11:24 PM train 050 8.137474e-01 66.421569
12/08 11:11:39 PM train 100 7.872147e-01 68.564356
12/08 11:11:55 PM train 150 8.082002e-01 67.715232
12/08 11:12:10 PM train 200 8.088563e-01 68.221393
12/08 11:12:25 PM train_acc 68.400000
12/08 11:12:31 PM valid 000 7.953624e-01 75.000000
12/08 11:12:38 PM valid_acc 56.666667
12/08 11:12:38 PM best_valid_acc 57.333333
12/08 11:12:38 PM epoch 39 lr 2.249913e-02
12/08 11:12:40 PM train 000 6.012206e-01 75.000000
12/08 11:12:59 PM train 050 7.479420e-01 68.137255
12/08 11:13:14 PM train 100 7.987457e-01 66.707921
12/08 11:13:29 PM train 150 7.953869e-01 67.715232
12/08 11:13:44 PM train 200 8.131572e-01 66.791045
12/08 11:13:59 PM train_acc 67.650000
12/08 11:14:04 PM valid 000 6.621497e-01 75.000000
12/08 11:14:12 PM valid_acc 53.333333
12/08 11:14:12 PM best_valid_acc 57.333333
12/08 11:14:12 PM epoch 40 lr 2.238001e-02
12/08 11:14:14 PM train 000 7.279578e-01 75.000000
12/08 11:14:30 PM train 050 7.210952e-01 73.284314
12/08 11:14:45 PM train 100 7.749778e-01 70.173267
12/08 11:15:01 PM train 150 7.954178e-01 68.791391
12/08 11:15:16 PM train 200 7.926288e-01 68.594527
12/08 11:15:31 PM train_acc 68.600000
12/08 11:15:35 PM valid 000 8.700464e-01 62.500000
12/08 11:15:41 PM valid_acc 52.000000
12/08 11:15:41 PM best_valid_acc 57.333333
12/08 11:15:41 PM epoch 41 lr 2.225845e-02
12/08 11:15:43 PM train 000 1.259213e+00 37.500000
12/08 11:15:59 PM train 050 7.983571e-01 68.382353
12/08 11:16:15 PM train 100 8.050355e-01 67.326733
12/08 11:16:30 PM train 150 7.914209e-01 68.708609
12/08 11:16:45 PM train 200 7.911139e-01 68.532338
12/08 11:17:00 PM train_acc 68.450000
12/08 11:17:03 PM valid 000 9.518012e-01 50.000000
12/08 11:17:11 PM valid_acc 52.666667
12/08 11:17:11 PM best_valid_acc 57.333333
12/08 11:17:11 PM epoch 42 lr 2.213448e-02
12/08 11:17:12 PM train 000 7.405713e-01 62.500000
12/08 11:17:29 PM train 050 7.952615e-01 64.705882
12/08 11:17:44 PM train 100 7.864767e-01 66.212871
12/08 11:17:59 PM train 150 8.000281e-01 66.721854
12/08 11:18:14 PM train 200 8.068151e-01 66.666667
12/08 11:18:29 PM train_acc 68.050000
12/08 11:18:33 PM valid 000 1.095594e+00 50.000000
12/08 11:18:42 PM valid_acc 52.000000
12/08 11:18:42 PM best_valid_acc 57.333333
12/08 11:18:42 PM epoch 43 lr 2.200814e-02
12/08 11:18:44 PM train 000 6.222906e-01 75.000000
12/08 11:19:00 PM train 050 8.078028e-01 68.872549
12/08 11:19:15 PM train 100 7.907636e-01 68.316832
12/08 11:19:31 PM train 150 7.901799e-01 68.129139
12/08 11:19:46 PM train 200 7.875958e-01 68.470149
12/08 11:20:01 PM train_acc 67.750000
12/08 11:20:03 PM valid 000 5.154288e-01 75.000000
12/08 11:20:12 PM valid_acc 53.333333
12/08 11:20:12 PM best_valid_acc 57.333333
12/08 11:20:12 PM epoch 44 lr 2.187945e-02
12/08 11:20:15 PM train 000 9.410931e-01 62.500000
12/08 11:20:32 PM train 050 8.671735e-01 64.950980
12/08 11:20:47 PM train 100 8.138792e-01 67.326733
12/08 11:21:02 PM train 150 8.110280e-01 68.294702
12/08 11:21:18 PM train 200 8.028703e-01 68.345771
12/08 11:21:33 PM train_acc 68.450000
12/08 11:21:36 PM valid 000 5.681499e-01 75.000000
12/08 11:21:45 PM valid_acc 52.000000
12/08 11:21:45 PM best_valid_acc 57.333333
12/08 11:21:45 PM epoch 45 lr 2.174845e-02
12/08 11:21:48 PM train 000 3.137651e-01 100.000000
12/08 11:22:05 PM train 050 8.323524e-01 63.970588
12/08 11:22:20 PM train 100 8.004375e-01 67.945545
12/08 11:22:35 PM train 150 8.004042e-01 68.046358
12/08 11:22:50 PM train 200 7.897332e-01 68.221393
12/08 11:23:05 PM train_acc 67.750000
12/08 11:23:10 PM valid 000 8.265582e-01 62.500000
12/08 11:23:19 PM valid_acc 52.000000
12/08 11:23:19 PM best_valid_acc 57.333333
12/08 11:23:19 PM epoch 46 lr 2.161517e-02
12/08 11:23:21 PM train 000 5.829108e-01 87.500000
12/08 11:23:37 PM train 050 7.739291e-01 68.872549
12/08 11:23:52 PM train 100 7.891307e-01 68.069307
12/08 11:24:07 PM train 150 7.771980e-01 69.039735
12/08 11:24:23 PM train 200 7.898790e-01 67.910448
12/08 11:24:38 PM train_acc 68.500000
12/08 11:24:41 PM valid 000 9.743583e-01 50.000000
12/08 11:24:50 PM valid_acc 55.333333
12/08 11:24:50 PM best_valid_acc 57.333333
12/08 11:24:50 PM epoch 47 lr 2.147964e-02
12/08 11:24:53 PM train 000 1.024470e+00 50.000000
12/08 11:25:09 PM train 050 8.368256e-01 66.911765
12/08 11:25:24 PM train 100 8.313120e-01 66.460396
12/08 11:25:40 PM train 150 7.983281e-01 68.625828
12/08 11:25:55 PM train 200 7.947746e-01 68.656716
12/08 11:26:10 PM train_acc 68.200000
12/08 11:26:14 PM valid 000 6.038988e-01 87.500000
12/08 11:26:22 PM valid_acc 54.000000
12/08 11:26:22 PM best_valid_acc 57.333333
12/08 11:26:22 PM epoch 48 lr 2.134190e-02
12/08 11:26:24 PM train 000 7.070577e-01 87.500000
12/08 11:26:40 PM train 050 7.690128e-01 67.892157
